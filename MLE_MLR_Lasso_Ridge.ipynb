{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <p style=\"text-align: center;\">MIS 382N: ADVANCED PREDICTIVE MODELING - MSBA</p>\n",
    "# <p style=\"text-align: center;\">Assignment 1</p>\n",
    "## <p style=\"text-align: center;\">Total points: 100</p>\n",
    "## <p style=\"text-align: center;\">Due: Tuesday, September 17 submitted via Canvas by 11:59 pm</p>\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Your partner needs to be from the same section. Only one student per team needs to submit the assignment on Canvas.  But be sure to include name and UTEID for both students.  Homework groups will be created and managed through Canvas, so please do not arbitrarily change your homework group. If you do change, let the TA know. \n",
    "\n",
    "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Challenges in Data Science (10 pts)\n",
    "\n",
    "Refer to the Domino guide under Modules --> Additional Resources\n",
    "\n",
    "Section 2 describes 8 Challenges. You may have personally encountered or heard of somebody else who encountered some of these challenge. If so,  please write 1-2 paragraphs on what situation was encountered and how it mapped into one the mentioned challenges. If not, think of a hypothetical case and do the same exercise. \n",
    "\n",
    "\n",
    "## Answer\n",
    "\n",
    "### Solve the right problem too slowly for it to matter (Challenge #4 as per the Domino Guide): \n",
    "\n",
    "###### During our experience at work, we were working as a part of the 'Customer Insights & Analytics' division for the retailer's Marketing team. One of the projects that we worked on, was building of the 'Behavioral Segments based Customer Lifetime Value' framework which would allow for (i) Identifying the right customers for targeting (ii) Estimating the amount of marketing funds to invest in them.\n",
    "\n",
    "###### The first version of the framework was built, with 15 behavioral customer segments and a 29% MAPE (Mean Absolute Prediction Error) in the holdout dataset. Eventhough the deadline for the project was met, and it was agreed that the models were up for use only after the final version was built and tested, there was an urgent requirement which was a response to a competitor's action. It was for targeting 'Millennial moms' with discounts on baby related products. One of our behavioral customer segments, called 'Young, multicultural, diverse millennial shoppers' contained the to-be-targeted millennial moms. The segment over indexed in millennials (4X), and with baby households (2.5X). Each one of the customers in this segment, had the first version of a LifeTimeValue score associated with them. Eventhough this was an urgent request, it was a part of a bigger strategic initiative, focusing on establishing long term relationship with millennial mothers (The idea was that, if they are able to establish a relationship with the mothers at such an important phase of their life, by providing trustworthy products for their babies, at low cost, then the entire family would become long term loyal customers for all their needs). Due to the importance of the strategic initiative involved, we were apprehensive of providing a less accurate value for the CLTV scores. \n",
    "\n",
    "###### However, this was a huge blunder as we missed out on an opportunity to create bottom-line impact for the retailer. The business was just looking for approximate measures to stratify their investments for marketing one of the many baby products. Bucketing the specific customer segment into 3 - H,M and L, and identifying the top group which has the highest future spends would have sufficed the marketing requirement. As per this heuristics, about ~93% of overall spend was from ~34% of the customers in that segment. This could have helped the retailer target the right customers, stratify their investments and achieve a relatively better ROI in that marketing activity. Further improvements could have been done later, and the best models could have been provided for the upcoming marketing exercises. Our biggest learning through this exercise was- 'As much as accuracy is important in Data Science, ultimately if it is not able to provide the right support to the business at the right time, then we are just incurring costs for the business through all the people, process and technology investments, as there is no tangible impact /  ROI'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: MLE Estimate (5+10+10 points)\n",
    "\n",
    "Consider a coin tossing experiment where a biased coin is tossed repeatedly for $n$ times with independence in successive tosses. \n",
    "If we record the outcome of each toss as $X_{i}$, for $i \\in \\{1,2,3,....,n\\}$ as follows\n",
    "\n",
    "$  \n",
    "X_{i} = \n",
    "     \\begin{cases}\n",
    "       \\text{1,} &\\quad\\text{if $i^{th}$ toss results in $Heads$,}\\\\\n",
    "       \\text{0,} &\\quad\\text{otherwise.} \\\\ \n",
    "     \\end{cases}\n",
    "$\n",
    "\n",
    "then $X_{1}, X_{2}, .... X_{n}$ will be a sequence of $0$'s and $1$'s. Assume that for this coin $P(Heads) = p$, which of course is not known to the experimenter. \n",
    "\n",
    "1. The log-likelihood function of the observations, as discussed in the class, denotes the probability of occurrence of the observations. Write the log-likelihood function for the set of observations $X_{1}, X_{2}, .... X_{n}$. \n",
    "\n",
    "2. Compute an MLE estimate of $p$.\n",
    "\n",
    "3. Check if the obtained estimate is unbiased.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Multiple Linear Regression in Python (30 pts)\n",
    "\n",
    "Use the following code to import the California housing prices dataset and linear models in python. The dataset is taken from https://www.kaggle.com/camnugent/california-housing-prices/version/1. I have removed the categorical variables and rows with missing variables to make it easier to run the models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"reduced_data.csv\")\n",
    "X_train = train_df.drop(['median_house_value'],axis=1)\n",
    "Y_train = train_df['median_house_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. (2 pts) Print the shape (number of rows and columns) of the feature matrix X, and print the first 5 rows.\n",
    "\n",
    "b.  (6 pts) Using ordinary least squares, fit a multiple linear regression (MLR) on all the feature variables using the entire dataset. Report the regression coefficient of each input feature and evaluate the model using mean absolute error (MAE).  Example of ordinary least squares in Python is shown in Section 1.1.1 of http://scikit-learn.org/stable/modules/linear_model.html.\n",
    "\n",
    "c.  (6 pts) Split the data into a training set and a test set, using the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) with test_size = 0.30 and random_state = 11. Fit an MLR using the training set.  Evaluate the trained model using the training set and the test set, respectively.  Compare the two MAE values thus obtained.\n",
    "\n",
    "d.  (5 pts) Calculate the pearson correlation matrix of the independent variables in the training set (you can use [this](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html)). Report the variables which have magnitude of correlation greater than 0.9 w.r.t the variable 'households'. \n",
    "\n",
    "e.  (6 pts) Add the following independent variables to both train and test sets:\n",
    "1. average_bedrooms = total_bedrooms/households\n",
    "2. average_rooms = total_rooms/households\n",
    "3. average_population = total_rooms/households\n",
    "\n",
    "Recalculate the correlation matrix. What do you observe about the correlation values of the above new variables?\n",
    "\n",
    "f. (5 pts) Fit an MLR on the new train data (with additional independent variables) and report the MAE on the new train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20433"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic checks to understand the dataset\n",
    "len(train_df) #20,433"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coefficients', array([-4.27301205e+04, -4.25097369e+04,  1.15790031e+03, -8.24972507e+00,\n",
      "        1.13820707e+02, -3.83855780e+01,  4.77013513e+01,  4.02975217e+04]))\n",
      "('Mean Absolute Error', 50799.6307289529)\n"
     ]
    }
   ],
   "source": [
    "#Creating a linear regression object\n",
    "linear_reg=linear_model.LinearRegression()\n",
    "\n",
    "#Training the model using our data\n",
    "linear_reg.fit(X_train,Y_train)\n",
    "\n",
    "#Printing co-efficients of the linear model\n",
    "print(\"Coefficients\", linear_reg.coef_)\n",
    "\n",
    "#Predicting the Y values for all rows in training dataset itself using the trained model\n",
    "Y_pred = linear_reg.predict(X_train)\n",
    "\n",
    "#MAE - Mean Absolute Error calculation\n",
    "print(\"Mean Absolute Error\",mean_absolute_error(Y_train,Y_pred)) #50799.63\n",
    "#How does this take in the same order? Forgot Python LOL!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean Absolute Error', 50749.10314465295)\n",
      "('Mean Absolute Error', 50916.74299435109)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_new, X_test_new, Y_train_new, Y_test_new = train_test_split(X_train, Y_train, test_size=0.3, random_state=11)\n",
    "#X_train and Y_train inside the function are the datasets which need to be split into train and test\n",
    "X_train_new[:5]\n",
    "\n",
    "len(X_train_new) #14,303 --> Train dataset --> 70% of the original\n",
    "len(X_test_new)  #6130 --> Test dataset --> 30% of the original\n",
    "\n",
    "#Fitting a linear model on the train dataset\n",
    "train_model=linear_reg.fit(X_train_new,Y_train_new)\n",
    "\n",
    "#Predicting y on the train dataset\n",
    "Y_pred_train_new = linear_reg.predict(X_train_new)\n",
    "#Calculating MAE for train dataset\n",
    "print(\"Mean Absolute Error\",mean_absolute_error(Y_train_new,Y_pred_train_new)) #50,749 - almost equal to training using the entire dataset as seen above\n",
    "\n",
    "#Predicting y on the test dataset\n",
    "Y_pred_test_new=linear_reg.predict(X_test_new)\n",
    "print(\"Mean Absolute Error\",mean_absolute_error(Y_test_new,Y_pred_test_new)) #50,916 - only 200 above the training error\n",
    "\n",
    "#The MAE from test dataset is slightly above the train dataset. However, it isn't that high either to raise doubts on overfitting. Good to go! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_rooms</th>\n",
       "      <td>0.042788</td>\n",
       "      <td>-0.034147</td>\n",
       "      <td>-0.356534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.927454</td>\n",
       "      <td>0.859323</td>\n",
       "      <td>0.916556</td>\n",
       "      <td>0.198486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bedrooms</th>\n",
       "      <td>0.069305</td>\n",
       "      <td>-0.066424</td>\n",
       "      <td>-0.316644</td>\n",
       "      <td>0.927454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880929</td>\n",
       "      <td>0.979547</td>\n",
       "      <td>-0.013082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>0.101596</td>\n",
       "      <td>-0.109600</td>\n",
       "      <td>-0.294652</td>\n",
       "      <td>0.859323</td>\n",
       "      <td>0.880929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910283</td>\n",
       "      <td>-0.001523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>0.056116</td>\n",
       "      <td>-0.070537</td>\n",
       "      <td>-0.298702</td>\n",
       "      <td>0.916556</td>\n",
       "      <td>0.979547</td>\n",
       "      <td>0.910283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                longitude  latitude  housing_median_age  total_rooms  \\\n",
       "total_rooms      0.042788 -0.034147           -0.356534     1.000000   \n",
       "total_bedrooms   0.069305 -0.066424           -0.316644     0.927454   \n",
       "population       0.101596 -0.109600           -0.294652     0.859323   \n",
       "households       0.056116 -0.070537           -0.298702     0.916556   \n",
       "\n",
       "                total_bedrooms  population  households  median_income  \n",
       "total_rooms           0.927454    0.859323    0.916556       0.198486  \n",
       "total_bedrooms        1.000000    0.880929    0.979547      -0.013082  \n",
       "population            0.880929    1.000000    0.910283      -0.001523  \n",
       "households            0.979547    0.910283    1.000000       0.008033  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation of all input variables in the train dataset\n",
    "X_corr_matrix=X_train_new.corr(method='pearson',min_periods=1)\n",
    "mask=X_corr_matrix['households']>0.9\n",
    "X_corr_matrix[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>average_bedrooms</th>\n",
       "      <th>average_rooms</th>\n",
       "      <th>average_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.925627</td>\n",
       "      <td>-0.111272</td>\n",
       "      <td>0.042788</td>\n",
       "      <td>0.069305</td>\n",
       "      <td>0.101596</td>\n",
       "      <td>0.056116</td>\n",
       "      <td>-0.020466</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>-0.027099</td>\n",
       "      <td>0.011811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>-0.925627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013098</td>\n",
       "      <td>-0.034147</td>\n",
       "      <td>-0.066424</td>\n",
       "      <td>-0.109600</td>\n",
       "      <td>-0.070537</td>\n",
       "      <td>-0.074943</td>\n",
       "      <td>0.062059</td>\n",
       "      <td>0.104294</td>\n",
       "      <td>-0.002330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_median_age</th>\n",
       "      <td>-0.111272</td>\n",
       "      <td>0.013098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.356534</td>\n",
       "      <td>-0.316644</td>\n",
       "      <td>-0.294652</td>\n",
       "      <td>-0.298702</td>\n",
       "      <td>-0.115736</td>\n",
       "      <td>-0.077163</td>\n",
       "      <td>-0.158539</td>\n",
       "      <td>0.012569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rooms</th>\n",
       "      <td>0.042788</td>\n",
       "      <td>-0.034147</td>\n",
       "      <td>-0.356534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.927454</td>\n",
       "      <td>0.859323</td>\n",
       "      <td>0.916556</td>\n",
       "      <td>0.198486</td>\n",
       "      <td>0.036170</td>\n",
       "      <td>0.146227</td>\n",
       "      <td>-0.031031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bedrooms</th>\n",
       "      <td>0.069305</td>\n",
       "      <td>-0.066424</td>\n",
       "      <td>-0.316644</td>\n",
       "      <td>0.927454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880929</td>\n",
       "      <td>0.979547</td>\n",
       "      <td>-0.013082</td>\n",
       "      <td>0.054525</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>-0.036556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>0.101596</td>\n",
       "      <td>-0.109600</td>\n",
       "      <td>-0.294652</td>\n",
       "      <td>0.859323</td>\n",
       "      <td>0.880929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910283</td>\n",
       "      <td>-0.001523</td>\n",
       "      <td>-0.062026</td>\n",
       "      <td>-0.072951</td>\n",
       "      <td>0.077684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>0.056116</td>\n",
       "      <td>-0.070537</td>\n",
       "      <td>-0.298702</td>\n",
       "      <td>0.916556</td>\n",
       "      <td>0.979547</td>\n",
       "      <td>0.910283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>-0.050050</td>\n",
       "      <td>-0.081950</td>\n",
       "      <td>-0.034892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_income</th>\n",
       "      <td>-0.020466</td>\n",
       "      <td>-0.074943</td>\n",
       "      <td>-0.115736</td>\n",
       "      <td>0.198486</td>\n",
       "      <td>-0.013082</td>\n",
       "      <td>-0.001523</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059447</td>\n",
       "      <td>0.350785</td>\n",
       "      <td>0.000417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_bedrooms</th>\n",
       "      <td>0.017548</td>\n",
       "      <td>0.062059</td>\n",
       "      <td>-0.077163</td>\n",
       "      <td>0.036170</td>\n",
       "      <td>0.054525</td>\n",
       "      <td>-0.062026</td>\n",
       "      <td>-0.050050</td>\n",
       "      <td>-0.059447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833841</td>\n",
       "      <td>-0.002194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_rooms</th>\n",
       "      <td>-0.027099</td>\n",
       "      <td>0.104294</td>\n",
       "      <td>-0.158539</td>\n",
       "      <td>0.146227</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>-0.072951</td>\n",
       "      <td>-0.081950</td>\n",
       "      <td>0.350785</td>\n",
       "      <td>0.833841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_population</th>\n",
       "      <td>0.011811</td>\n",
       "      <td>-0.002330</td>\n",
       "      <td>0.012569</td>\n",
       "      <td>-0.031031</td>\n",
       "      <td>-0.036556</td>\n",
       "      <td>0.077684</td>\n",
       "      <td>-0.034892</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>-0.002194</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    longitude  latitude  housing_median_age  total_rooms  \\\n",
       "longitude            1.000000 -0.925627           -0.111272     0.042788   \n",
       "latitude            -0.925627  1.000000            0.013098    -0.034147   \n",
       "housing_median_age  -0.111272  0.013098            1.000000    -0.356534   \n",
       "total_rooms          0.042788 -0.034147           -0.356534     1.000000   \n",
       "total_bedrooms       0.069305 -0.066424           -0.316644     0.927454   \n",
       "population           0.101596 -0.109600           -0.294652     0.859323   \n",
       "households           0.056116 -0.070537           -0.298702     0.916556   \n",
       "median_income       -0.020466 -0.074943           -0.115736     0.198486   \n",
       "average_bedrooms     0.017548  0.062059           -0.077163     0.036170   \n",
       "average_rooms       -0.027099  0.104294           -0.158539     0.146227   \n",
       "average_population   0.011811 -0.002330            0.012569    -0.031031   \n",
       "\n",
       "                    total_bedrooms  population  households  median_income  \\\n",
       "longitude                 0.069305    0.101596    0.056116      -0.020466   \n",
       "latitude                 -0.066424   -0.109600   -0.070537      -0.074943   \n",
       "housing_median_age       -0.316644   -0.294652   -0.298702      -0.115736   \n",
       "total_rooms               0.927454    0.859323    0.916556       0.198486   \n",
       "total_bedrooms            1.000000    0.880929    0.979547      -0.013082   \n",
       "population                0.880929    1.000000    0.910283      -0.001523   \n",
       "households                0.979547    0.910283    1.000000       0.008033   \n",
       "median_income            -0.013082   -0.001523    0.008033       1.000000   \n",
       "average_bedrooms          0.054525   -0.062026   -0.050050      -0.059447   \n",
       "average_rooms             0.004237   -0.072951   -0.081950       0.350785   \n",
       "average_population       -0.036556    0.077684   -0.034892       0.000417   \n",
       "\n",
       "                    average_bedrooms  average_rooms  average_population  \n",
       "longitude                   0.017548      -0.027099            0.011811  \n",
       "latitude                    0.062059       0.104294           -0.002330  \n",
       "housing_median_age         -0.077163      -0.158539            0.012569  \n",
       "total_rooms                 0.036170       0.146227           -0.031031  \n",
       "total_bedrooms              0.054525       0.004237           -0.036556  \n",
       "population                 -0.062026      -0.072951            0.077684  \n",
       "households                 -0.050050      -0.081950           -0.034892  \n",
       "median_income              -0.059447       0.350785            0.000417  \n",
       "average_bedrooms            1.000000       0.833841           -0.002194  \n",
       "average_rooms               0.833841       1.000000            0.003475  \n",
       "average_population         -0.002194       0.003475            1.000000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding new variables for the above 3 - normalized by number of households \n",
    "X_train_new['average_bedrooms']=X_train_new['total_bedrooms']/X_train_new['households']\n",
    "X_train_new['average_rooms']=X_train_new['total_rooms']/X_train_new['households']\n",
    "X_train_new['average_population']=X_train_new['population']/X_train_new['households']\n",
    "X_train_new.corr(method='pearson')\n",
    "\n",
    "#The normalized metrics exhibit no correlation with the number of households \n",
    "#This is because, if there is almost perfect correlation between number of households and these variables (bedrooms, rooms, population), \n",
    "#...then the per household metric, should remain constant. It wouldn't change with the increasing number of households"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independent variables having correlation greater than 0.9 w.r.t 'households': \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean Absolute Error', 50474.268791457886)\n",
      "('Mean Absolute Error', 50783.974603927876)\n"
     ]
    }
   ],
   "source": [
    "#Fitting linear model again, after adding the new normalized metrics\n",
    "#The train dataset already contains the new metrics, so no changes made\n",
    "train_model_addvar=linear_reg.fit(X_train_new,Y_train_new)\n",
    "\n",
    "#Adding the new variables in the test dataset\n",
    "X_test_new['average_bedrooms']=X_test_new['total_bedrooms']/X_test_new['households']\n",
    "X_test_new['average_rooms']=X_test_new['total_rooms']/X_test_new['households']\n",
    "X_test_new['average_population']=X_test_new['population']/X_test_new['households']\n",
    "\n",
    "#Predicting y on the new train dataset\n",
    "Y_pred_train_new_addvar = linear_reg.predict(X_train_new)\n",
    "\n",
    "\n",
    "#Calculating MAE for addvar train dataset\n",
    "print(\"Mean Absolute Error\",mean_absolute_error(Y_train_new,Y_pred_train_new_addvar)) #50,474  \n",
    "\n",
    "#Predicting y on the addvar test dataset\n",
    "Y_pred_test_new_addvar=linear_reg.predict(X_test_new)\n",
    "print(\"Mean Absolute Error\",mean_absolute_error(Y_test_new,Y_pred_test_new_addvar)) #50,783\n",
    "\n",
    "#Both the training errors and test errors have come down!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Ridge and Lasso Regression (30 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same data from before, in this question you will explore the application of Lasso and Ridge regression using sklearn package in Python. Use the same train and test data with additional augmented columns from before. Scale the data so that each of the dependent variables have zero mean and unit variance. You can use the [sklearn.preprocessing.scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html) function for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Use sklearn.linear_model.Lasso and sklearn.linear_model.Ridge classes to do a [5-fold cross validation](http://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#example-exercises-plot-cv-diabetes-py) using sklearn's [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html). For the sweep of the regularization parameter, we will look at a grid of values ranging from $\\lambda = 10^{10}$ to $\\lambda = 10^{-2}$. In Python, you can consider this range of values as follows:\n",
    "\n",
    "      import numpy as np\n",
    "\n",
    "      alphas =  10**np.linspace(10,-2,100)*0.5\n",
    "\n",
    "  Report the best chosen $\\lambda$ based on cross validation. The cross validation should happen on your training data using  average MAE as the scoring metric. (8pts)\n",
    "\n",
    "2) Run ridge and lasso for all of the alphas specified above (on training data), and plot the coefficients learned for each of them - there should be one plot each for lasso and ridge, so a total of two plots; the plots for different features for a method should be on the same plot. What do you qualitatively observe when value of the regularization parameter is changed? (7pts)\n",
    "\n",
    "3) Run least squares regression, ridge, and lasso on the training data. For ridge and lasso, use only the best regularization parameter. Report the prediction error (MAE) on the test data for each. (5pts)\n",
    "\n",
    "4) Run lasso again with cross validation using [sklearn.linear_model.LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html). Set the cross validation parameters as follows:\n",
    "\n",
    "    LassoCV(alphas=None, cv=10, max_iter=10000)\n",
    "\n",
    "Report the best $\\lambda$ based on cross validation. Run lasso on the training data using the best $\\lambda$ and report the coefficeints for all variables. (5pts)\n",
    "\n",
    "5) Why did we have to scale the data before regularization? (5pts)\n",
    "\n",
    "\n",
    "## Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the data to have zero mean and unit variance\n",
    "import sklearn\n",
    "X_train_new_1=sklearn.preprocessing.scale(X_train_new,with_mean=True,with_std=True,copy=True)\n",
    "Y_train_new_1=sklearn.preprocessing.scale(Y_train_new,with_mean=True,with_std=True,copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=10000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=11,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'alpha': array([5.00000e+09, 3.78232e+09, ..., 6.60971e-03, 5.00000e-03])}],\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, RidgeCV, LassoCV\n",
    "from sklearn.model_selection import KFold, GridSearchCV #General cross validation which can be used for lasso and ridge?\n",
    "#Verify understanding\n",
    "import numpy as np\n",
    "\n",
    "#Defining lasso model\n",
    "lasso = Lasso(random_state=11, max_iter=10000)\n",
    "alphas =  10**np.linspace(10,-2,100)*0.5\n",
    "tuned_parameters = [{'alpha': alphas}]\n",
    "n_folds = 5\n",
    "\n",
    "#Setting up cross validation skeleton using lasso as the model\n",
    "cross_val = GridSearchCV(lasso, tuned_parameters, cv=n_folds, refit=False)\n",
    "\n",
    "#Fitting the model to the train_new_1 'scaled' dataset (contains additional normalized variables as well)\n",
    "cross_val.fit(X_train_new_1,Y_train_new_1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "scores = cross_val.cv_results_['mean_test_score']\n",
    "scores_std = cross_val.cv_results_['std_test_score']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x118c4ba8>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure().set_size_inches(8, 6)\n",
    "plt.semilogx(alphas, std_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000000000.0, 0.005)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot error lines showing +/- std. errors of the scores\n",
    "std_error = scores_std / np.sqrt(n_folds)\n",
    "plt.semilogx(alphas, scores + std_error, 'b--')\n",
    "plt.semilogx(alphas, scores - std_error, 'b--')\n",
    "plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
    "plt.ylabel('CV score +/- std error')\n",
    "plt.xlabel('alpha')\n",
    "\n",
    "plt.axhline(np.max(scores), linestyle='--', color='.5')\n",
    "plt.xlim([alphas[0], alphas[-1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting ridge coefficents as a function of the regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting lasso coefficents as a function of the regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the alpha parameter obtained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit lasso using the above alpha and report MAE on Test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (5pts)\n",
    "\n",
    "How do you think the performance of your model varies in the train and test set as you increase(decrease) the number of examples in the training dataset? Explain why does it change in a particular way.\n",
    "\n",
    "Increase in the number of observations in the training set, increases the variance, which is a measure of the spread / variation in the actual data. This will make the model more robust and adaptable to different sets of data points, and is expected to yield similar accuracy levels across different validation datasets. \n",
    "\n",
    "Alternatively, decrease in the number of observations, decreases the 'variation representation' of the actual data, causing the model to be very specific (biased) to the data points in hand. Theoretically, this model will be less robust and cannot be applied to different datasets without significant compromise in accuracy.  \n",
    "\n",
    "However, when the training dataset is a sample, whose mean and standard deviation are almost exactly equal to the population mean and standard deviation, then increasing the sample size will not have much effect on the model performance. But however, this is an ideal case scenario and the likelihood of this happening is almost equal to 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
